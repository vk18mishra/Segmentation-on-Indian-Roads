# -*- coding: utf-8 -*-
"""CANET Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ntpN5y37E5yTawbL0u0Q5fP1BcC4n4Xb
"""

import tensorflow as tf
# tf.compat.v1.enable_eager_execution()
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import UpSampling2D
from tensorflow.keras.activations import relu
from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.layers import Multiply
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, Add, Multiply, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.initializers import glorot_uniform
K.set_image_data_format('channels_last')
K.set_learning_phase(1)

class convolutional_block(tf.keras.layers.Layer):
    def __init__(self, kernel=3,  filters=[4,4,8], stride=2, name="conv block"):
        super().__init__(name=name)
        self.F1, self.F2, self.F3 = filters
        self.kernel = kernel
        self.stride = stride
        self.conv1 = Conv2D(self.F1,kernel_size=(1,1),strides=(self.stride,self.stride))
        self.bn1     = BatchNormalization()
        self.bn2     =  BatchNormalization()
        self.bn3     =  BatchNormalization()
        self.bn4     =  BatchNormalization()
        self.act1=Activation('relu') 
        self.act2=Activation('relu') 
        self.act3=Activation('relu')  
        self.act4=Activation('relu')  
        self.conv2 = Conv2D(self.F2,kernel_size=(3,3),padding='same')
        self.conv3 = Conv2D(self.F3,kernel_size=(1,1))
        self.conv_parallel = Conv2D(self.F3,kernel_size=(3,3),strides=(self.stride,self.stride),padding='same')
        self.add = Add()
    def call(self, X):
        # write the architecutre that was mentioned above
        conv_1 = self.conv1(X)
        bn_1   = self.bn1(conv_1)
        act_1   = self.act1(bn_1)
        conv_2 = self.conv2(act_1)
        bn_2   = self.bn2(conv_2)
        act_2   = self.act2(bn_2)
        conv_3 = self.conv3(act_2)
        bn_3   = self.bn3(conv_3)

        # parallel
        conv_p = self.conv_parallel(X)
        bn_4   = self.bn4(conv_p)
        act_3   = self.act3(bn_4)
        # element wise sum
        ele_sum = self.add((act_3,bn_3))
        
        X = self.act4(ele_sum)

        return X

class identity_block(tf.keras.layers.Layer):
    def __init__(self, kernel=3,  filters=[4,4,8], name="identity block"):
        super().__init__(name=name)
        self.F1, self.F2, self.F3 = filters
        self.kernel = kernel
        self.conv1 = Conv2D(self.F1, kernel_size=(1,1), strides=(1,1), kernel_initializer=glorot_uniform(seed=21))
        self.bn1 = BatchNormalization(axis=3)
        self.act1 = Activation('relu')

        self.conv2 = Conv2D(self.F2, kernel_size=self.kernel, strides=(1,1), padding='same', kernel_initializer=glorot_uniform(seed=21))
        self.bn2 = BatchNormalization(axis=3)
        self.act2 = Activation('relu')

        self.conv3 = Conv2D(self.F3, kernel_size=(1,1), strides=(1,1), kernel_initializer=glorot_uniform(seed=21))
        self.bn3 = BatchNormalization(axis=3)

        self.add1 = Add()
        self.act3 = Activation('relu')

    def call(self, X):
        # write the architecutre that was mentioned above
        x = self.conv1(X)
        x = self.bn1(x)
        x = self.act1(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.act2(x)

        x = self.conv3(x)
        x = self.bn3(x)

        x = self.add1((x, X))
        X = self.act3(x)
        
        return X

class global_flow(tf.keras.layers.Layer):
    def __init__(self, name="global_flow"):
        super().__init__(name=name)
        #using average pooling as global pooling changes the shape
        self.GF_Pool = AveragePooling2D(1,(32,32))                        
        self.GF_BN = BatchNormalization()                          
        self.GF_Act = Activation('relu')   
        self.GF_C1 = Conv2D(64, (1, 1), padding = 'same', activation = 'relu', name = 'GF_C1' )
        self.GF_C_T = Conv2DTranspose(64, (32,32), use_bias = False)

    def call(self, X):
        # implement the global flow operation
        #using average pooling as global pooling changes the shape
        x = self.GF_Pool(X)                          
        x = self.GF_BN(x)                          
        x = self.GF_Act(x)    
        x = self.GF_C1(x)
        X = self.GF_C_T(x)

        return X

class context_flow(tf.keras.layers.Layer):    
    def __init__(self, name="context_flow"):
        super().__init__(name=name)
        self.concat1 = Concatenate()
        self.CF_Pool = AveragePooling2D((1, 1),  (2, 2))
        self.CF_C1 = Conv2D(64, (3, 3), padding = 'same')
        self.CF_C2 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')
        self.CF_C3 = Conv2D(64, (1, 1), padding = 'same', activation = 'relu')
        self.CF_Act1 = Activation('relu')
        self.CF_C4 = Conv2D(64, (1, 1), padding = 'same', activation = 'relu')
        self.CF_Act2 = Activation('sigmoid')
        self.CF_Mul = Multiply()
        self.CF_Add = Add()
        self.CF_C_T = Conv2DTranspose(64,  (17, 17), use_bias = False )

    def call(self, X):
        # implement the context flow as mentioned in the above cell
        X = self.concat1(X)
        x = self.CF_Pool(X)
        x = self.CF_C1(x)
        conv2 = self.CF_C2(x)
        x = self.CF_C3(conv2)
        x = self.CF_Act1(x)
        x = self.CF_C4(x)
        x = self.CF_Act2(x)
        x = self.CF_Mul((conv2 , x))
        x = self.CF_Add((conv2,x))
        X = self.CF_C_T(x)
        return X

class fsm(tf.keras.layers.Layer):    
    def __init__(self, name="feature_selection"):
        super().__init__(name=name)
        #print("FSM1:",X.shape)
        self.FSM_C1 = Conv2D(64, kernel_size=(3, 3), padding = 'same', activation = 'relu', name = 'FSM_C1')
        self.FSM_Pool = AveragePooling2D(32, name = 'FSM_Pool')
        #print("FSM2:",FSM_Pool.shape)
        self.FSM_C2 = Conv2D(64, kernel_size=(1, 1), padding = 'same', activation = 'relu', name = 'FSM_C2')
        self.BN_1 = BatchNormalization()
        self.Act_1 = Activation('sigmoid')
        #print("FSM3:",Act_1.shape)
        self.FSM_Mul = Multiply()
        self.FSM_C_T = Conv2DTranspose(32,  kernel_size=(33, 33), use_bias = False )
        #FSM_Conv_T = Multiply()([FSM_C1,FSM_C_T])
        # print("FSM Output:",FSM_C_T.shape)

    def call(self, X):
        # implement the FSM modules based on image in the above cells
        #print("FSM1:",X.shape)
        conv1 = self.FSM_C1(X)
        x = self.FSM_Pool(conv1)
        #print("FSM2:",FSM_Pool.shape)
        x = self.FSM_C2(x)
        x = self.BN_1(x)
        x = self.Act_1(x)
        #print("FSM3:",Act_1.shape)
        x = self.FSM_Mul((conv1,x))
        X = self.FSM_C_T(x)
        #FSM_Conv_T = Multiply()([FSM_C1,FSM_C_T])
        # print("FSM Output:",FSM_C_T.shape)
        return X

class agcn(tf.keras.layers.Layer):    
    def __init__(self, name="global_conv_net"):
        super().__init__(name=name)
        self.AGCN_1 = Conv2D(32, kernel_size=(7, 1),  strides=(1,1), activation = 'relu', padding = 'same')
        self.AGCN_2 = Conv2D(32, (1, 7), activation = 'relu', padding = 'same', name = 'AG_conv2')

        self.AGCN_3 = Conv2D(32, kernel_size=(1, 7), strides=(1,1), activation = 'relu', padding = 'same')
        self.AGCN_4 = Conv2D(32, kernel_size=(7, 1), strides=(1,1), activation = 'relu', padding = 'same')

        self.X1 = Add()

        self.X2 = Conv2D(32, kernel_size=(3, 3), strides=(1,1), activation = 'relu', padding = 'same')

        self.X3 = Add()

    def call(self, X_concat_agcn):
        # please implement the above mentioned architecture
        x1 = self.AGCN_1(X_concat_agcn)
        x1 = self.AGCN_2(x1)

        x2 = self.AGCN_3(X_concat_agcn)
        x2 = self.AGCN_4(x2)

        x3 = self.X1((x1,x2))

        x4 = self.X2(x3)

        X = self.X3((x3,x4))
        return X

tf.keras.backend.set_image_data_format('channels_last')
tf.keras.backend.clear_session()

X_input = Input(shape=(256,256,3))

# Stage 1
X = Conv2D(64, (3, 3), name='conv1', padding="same", kernel_initializer=glorot_uniform(seed=0))(X_input)
X = BatchNormalization(axis=3, name='bn_conv1')(X)
X = Activation('relu')(X)
X = MaxPooling2D((2, 2), strides=(2, 2))(X)
print("Stage_1(before C1):",X.shape)

# Stage 2 [C1]
X_concat_agcn = convolutional_block(3, [4, 4, 8], 2, name='C1').call(X)
# X_concat_agcn = X_concat_agcn.call()
# print('ggg',X_concat_agcn.shape)
X = identity_block(kernel=3, filters=[4, 4, 8], name='id1').call(X_concat_agcn)
# X = X.call()
print('[C1]:',X.shape)

# Stage 3 [C2]
X = convolutional_block(kernel=3, filters=[8, 8, 16], stride=2, name='C2').call(X)
X = identity_block(kernel=3, filters=[8, 8, 16], name='id21').call(X)
X = identity_block(kernel=3, filters=[8, 8, 16], name='id22').call(X)
print('[C2]:',X.shape)

# Stage 4 [C3]
X = convolutional_block(kernel=3, filters=[16, 16, 32], stride=1, name='C3').call(X)
X = identity_block(kernel=3, filters=[16, 16, 32], name='id31').call(X)
X = identity_block(kernel=3, filters=[16, 16, 32], name='id32').call(X)
X = identity_block(kernel=3, filters=[16, 16, 32], name='id33').call(X)
print('[C3]:',X.shape)

# Stage 5 [C4]
X = convolutional_block(kernel=3, filters=[32, 32, 64], stride=1, name='C4').call(X)
X = identity_block(kernel=3, filters=[32, 32, 64], name='id41').call(X)
X = identity_block(kernel=3, filters=[32, 32, 64], name='id42').call(X)
X = identity_block(kernel=3, filters=[32, 32, 64], name='id43').call(X)
C4_output = identity_block(kernel=3, filters=[32, 32, 64], name='id44').call(X)
print('[C4]:',C4_output.shape)

        #return [X, X_concat_agcn]

# write the complete architecutre

# X_input = Input(shape=(256,256,3))

# channel_maps_list = channel_maps.call()
# C4_output = channel_maps_list[0]
# X_cancat_agcn = channel_maps_list[1]

GF_output = global_flow(name="global_flow").call(C4_output)
# C4_concat_GF = Concatenate()([C4_output,GF_output])

CF_1_output = context_flow(name='CF1').call([C4_output,GF_output])
# C4_concat_CF1 = Concatenate()([C4_output,CF_1_output])

CF_2_output = context_flow(name='CF2').call([C4_output,CF_1_output])
# C4_concat_CF2 = Concatenate()([C4_output,CF_2_output])

CF_3_output = context_flow(name='CF3').call([C4_output,CF_2_output])

GF_add_CFs = Add(name = 'GF_add_CFs')((GF_output, CF_1_output, CF_2_output, CF_3_output))

FSM_output = fsm(name="feature_selection").call(GF_add_CFs)

# Conv_main = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', name = 'FS_Conv3')(FSM_output)
AGCN_output = agcn(name="global_conv_net").call(X_concat_agcn)

# upsamp_main_1 = UpSampling2D((2,2), interpolation='bilinear')(Conv_main) #(Conv2DTranspose(nClasses , (113,113), use_bias = False ))(mid_Conv)
# upsamp_main_2 = UpSampling2D((2,2), interpolation='bilinear')(AGCN_output)
concat_main = concatenate((FSM_output,AGCN_output))
Last_conv = Conv2D(21, (3, 3), activation = 'relu', padding = 'same', name = 'Last_conv')(concat_main)
    
upsamp_main_3  = UpSampling2D((4,4), interpolation = 'bilinear')(Last_conv)
output = (Activation('softmax'))(upsamp_main_3)
print('output:', output.shape)


model = Model(inputs = X_input, outputs = output, name='CANET')

model.summary()

tf.keras.utils.plot_model(
    model, to_file='model_canet.png', show_shapes=True, show_layer_names=True,
    expand_nested=False, rankdir='TB')

import tensorflow as tf
#tensorflow.config.run_functions_eagerly(True)
tf.config.experimental_run_functions_eagerly(True)
# tf.enable_eager_execution()
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
# from hilbert import hilbertCurve
import imgaug.augmenters as iaa
import numpy as np
# import albumentations as A
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

from tensorflow.keras import layers
from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten, LSTM, BatchNormalization, ReLU, Reshape
from tensorflow.keras.models import Model
import random as rn

!pip install imgaug

from tensorflow.keras.layers import Flatten

from sklearn.model_selection import train_test_split
X_train, X_test = train_test_split(data_df, test_size=0.12, random_state=42)
X_train.shape, X_test.shape

# import imgaug.augmenters as iaa
# For the assignment choose any 4 augumentation techniques
# check the imgaug documentations for more augmentations
aug2 = iaa.Fliplr(1)
aug3 = iaa.Flipud(1)
aug4 = iaa.Emboss(alpha=(1), strength=1)
aug5 = iaa.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))
#aug6 = iaa.Sharpen(alpha=(1.0), lightness=(1.5))

def visualize(**images):
    n = len(images)
    plt.figure(figsize=(16, 5))
    for i, (name, image) in enumerate(images.items()):
        plt.subplot(1, n, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.title(' '.join(name.split('_')).title())
        if i==1:
            plt.imshow(image, cmap='gray', vmax=1, vmin=0)
        else:
            plt.imshow(image)
    plt.show()
    
# def normalize_image(mask):
#     mask = mask/255
#     return mask

class Dataset:
    # we will be modifying this CLASSES according to your data/problems
    CLASSES = list_classes
    
    # the parameters needs to changed based on your requirements
    # here we are collecting the file_names because in our dataset, both our images and maks will have same file name
    # ex: fil_name.jpg   file_name.mask.jpg
    def __init__(self, file_names, classes, train_sett):
        
        ###self.ids = file_names
        # the paths of images
        self.images_fps   = list(file_names['image'])###[os.path.join(images_dir, image_id+'.jpg') for image_id in self.ids]
        # the paths of segmentation images
        self.masks_fps    = list(file_names['mask'])###[os.path.join(images_dir, image_id+".mask.jpg") for image_id in self.ids]
        # the paths of json files
        # self.json_fps     = file_names['json']
        # giving labels for each class
        self.class_values = [self.CLASSES.index(cls) for cls in classes]
        self.train_sett = train_sett
        self.w = 256
        self.h = 256
    
    def __getitem__(self, i):
        
        # read data

        # self.w, self.h, self.labels_d, self.vertexlist_d = get_poly(self.json_fps[i])

        ###image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)

        image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED) 
        image = cv2.resize(image,(self.w,self.h),interpolation=cv2.INTER_NEAREST)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image_mask  = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)/10
        image_mask = cv2.resize(image_mask,(self.w,self.h),interpolation=cv2.INTER_NEAREST)
        ###image_mask = normalize_image(mask)

        
        image_masks = [(image_mask == v) for v in self.class_values]
        image_mask = np.stack(image_masks, axis=-1).astype('float')
   
        if self.train_sett=='train':
            a = np.random.uniform()
            if a<0.3:
                image = aug2.augment_image(image)
                image_mask = aug2.augment_image(image_mask)
            elif a<0.6:
                image = aug3.augment_image(image)
                image_mask = aug3.augment_image(image_mask)
            elif a<0.8:
                image = aug4.augment_image(image)
                image_mask = aug4.augment_image(image_mask)
            else:
                image = aug5.augment_image(image)
                image_mask = image_mask
            
        return image, image_mask
        
    def __len__(self):
        return len(self.ids)
    
    
class Dataloder(tf.keras.utils.Sequence):    
    def __init__(self, dataset, batch_size=1, len_shape=3527, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len_shape)

    def __getitem__(self, i):
        
        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            data.append(self.dataset[j])
        
        batch = [np.stack(samples, axis=0) for samples in zip(*data)]
        
        return tuple(batch)
    
    def __len__(self):
        return len(self.indexes) // self.batch_size
    
    def on_epoch_end(self):
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)

!pip install -U segmentation-models==0.2.1

#Remove Previous Logs
import shutil
shutil.rmtree('logs\Model_CaNet', ignore_errors=True)

# https://github.com/qubvel/segmentation_models
import segmentation_models as sm
from segmentation_models.metrics import iou_score
from segmentation_models import Unet
import tensorflow
import keras
#from keras.optimizers import Adam

optim = tensorflow.keras.optimizers.Adam(learning_rate=0.000262)

focal_loss = sm.losses.cce_dice_loss

# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses
# total_loss = sm.losses.binary_focal_dice_loss 
# or total_loss = sm.losses.categorical_focal_dice_loss 

model.compile(optimizer = optim, loss = focal_loss, metrics=[iou_score])

#Function for Custom Callback for Implementing Micro Averaged F1 Score as the Metric
import numpy as np
from tensorflow.keras.callbacks import Callback
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
# class Metrics(Callback):
#   def __init__(self, interval=1):
#     super(Callback, self).__init__()
#     self.interval = interval
#     #self.X_val, self.y_val = validation_data
#   #def on_train_begin(self, logs={}):
  
#   def on_epoch_end(self, epoch, logs={}):
#     if epoch % self.interval == 0:
#       #Checking Overfitting after achieving desired val_iou_score
#       # if logs.get('val_iou_score')>0.40:# and logs.get('accuracy')>0.75:
#       # #if (logs.get('accuracy')-logs.get('val_accuracy'))>0.06:
#       #     print("Required Metric Value Reached, hence terminated at epoch {} to prevent overfitting".format(epoch))
#       #     self.model.stop_training = True
#       # return
#       if (logs.get('iou_score')-logs.get('val_iou_score'))>0.38 and logs.get('iou_score')>=0.40:
#           print("Overfitting started, hence terminated at epoch {} to prevent furthur overfitting".format(epoch))
#           self.model.stop_training = True
#       return
 
# metrics = Metrics(interval=1)

import keras, datetime
# Dataset for train images
CLASSES = list_classes
train_dataset = Dataset(X_train, classes=CLASSES, train_sett='train')
test_dataset  = Dataset(X_test, classes=CLASSES, train_sett='test')


train_dataloader = Dataloder(train_dataset, batch_size=32, len_shape=3527, shuffle=True)
test_dataloader = Dataloder(test_dataset, batch_size=32, len_shape=481, shuffle=True)

print(train_dataloader[0][0].shape, train_dataloader[0][1].shape)
BATCH_SIZE = 32
assert train_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)
assert train_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, 21)

# define callbacks for learning rate scheduling and best checkpoints saving
NAME = "Model_CaNet"
# define callbacks for learning rate scheduling and best checkpoints saving
callbacks = [
    tensorflow.keras.callbacks.TensorBoard(log_dir='logs\{}'.format(NAME),update_freq='epoch'),
    tensorflow.keras.callbacks.ModelCheckpoint('./best_model_canet.h5', save_weights_only=True, save_best_only=True, \
                                       mode='max', monitor='val_iou_score'),
    tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.00000001,patience=3)
]

test_dataloader[0][0].shape, test_dataloader[0][1].shape

!rm -rf /logs

history_canet = model.fit(train_dataloader, steps_per_epoch=len(train_dataloader), 
                              epochs=100, validation_data=test_dataloader,callbacks=callbacks)

# Plot training & validation iou_score values
plt.figure(figsize=(30, 5))
plt.subplot(121)
plt.plot(history_canet.history['iou_score'])
plt.plot(history_canet.history['val_iou_score'])
plt.title('Model iou_score')
plt.ylabel('iou_score')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

# Plot training & validation loss values
plt.subplot(122)
plt.plot(history_canet.history['loss'])
plt.plot(history_canet.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

X_test_ex = X_test.head(10)
for p in range(10):
    #original image
    image = cv2.imread(list(X_test_ex['image'])[p], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (256,256),interpolation = cv2.INTER_NEAREST) 
    
    #predicted segmentation map
    pred_mask  = model.predict(image[np.newaxis,:,:,:])
    pred_mask = tf.argmax(pred_mask, axis=-1)
    
    #original segmentation map
    image_mask = cv2.imread(list(X_test_ex['mask'])[p], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (256,256),interpolation = cv2.INTER_NEAREST)
    

    plt.figure(figsize=(10,6))
    plt.subplot(131)
    plt.imshow(image)
    plt.subplot(132)
    plt.imshow(image_mask, cmap='gray') 
    plt.subplot(133)
    plt.imshow(pred_mask[0], cmap='gray')
    plt.show()