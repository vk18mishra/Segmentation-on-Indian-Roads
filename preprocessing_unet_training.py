# -*- coding: utf-8 -*-
"""Preprocessing & UNet Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UZdRdjp6NkBEHHAzneMmnDbFyYnNdP_5

# Segmentation of Indian Traffic
"""

!pip install tensorflow==2.2.0
!pip install keras==2.3.1

import math
from PIL import Image, ImageDraw
from PIL import ImagePath
import pandas as pd
import os
from os import path
from tqdm import tqdm
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
import urllib

"""# Task 1: Preprocessing"""

#Loading Data through Google Drive
# Install the PyDrive wrapper & import libraries.
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

file_id = '1uFqgly3XZefQlE8OXUl5CUei3Mh7yhmd'
downloaded = drive.CreateFile({'id':file_id})
downloaded.FetchMetadata(fetch_all=True)
downloaded.GetContentFile(downloaded.metadata['title'])

#Loading data.zip through curlwget
# !wget --header="Host: doc-00-90-docs.googleusercontent.com" --header="User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36" --header="Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9" --header="Accept-Language: en-US,en;q=0.9,es;q=0.8" --header="Cookie: AUTH_j9bcrmgt4omen2e6cvbm2ejader83m0d_nonce=0htrs50lkrigm" --header="Connection: keep-alive" "https://doc-00-90-docs.googleusercontent.com/docs/securesc/gav8itevci1g4kd0q1cuucl5an9d430s/npkcu2rijhd5bpm1vr3997fvodsafjhg/1605533550000/00484516897554883881/05016653509110039968/1iQ93IWVdR6dZ6W7RahbLq166u-6ADelJ?e=download&authuser=0&nonce=0htrs50lkrigm&user=05016653509110039968&hash=a6i4pesktp8bmu2ol5ko0gjih4i3kn5o" -c -O 'data.zip'

!unzip 'data.zip'
#print("Data is Loaded")

"""## 1. Get all the file name and corresponding json files"""

frames_list = os.listdir('data/images')
images_file = []
for i in frames_list:
  dir_img = 'data/images/'+i
  dir_mask = 'data/mask/'+i
  directory = os.fsencode(dir_img)
  for file in (os.listdir(directory)):
      filename = os.fsdecode(file)
      if filename.endswith(".jpg"):
        tmp = dir_img+'/'+filename
        images_file.append(tmp)
len(images_file)

masks_file = []
for i in images_file:
  file_chk1 = i.split(sep='_')[0]
  file_chk = 'data/mask/'+file_chk1.split(sep='/')[2]
  file_mask_chk = 'data/mask/'+file_chk.split(sep='/')[2]+'/'+file_chk1.split(sep='/')[3]
  frame_chk = file_chk1.split(sep='/')[3]
  directory = os.fsencode(file_chk)
  for file in (os.listdir(directory)):
      filename = os.fsdecode(file)
      mask_frame_chk = filename.split(sep='_')[0]
      if mask_frame_chk==frame_chk:
        tmp1 = filename.split(sep='_')[1]
        tmp = file_mask_chk+'_'+tmp1+'_'+filename.split(sep='_')[2]
        masks_file.append(tmp)
len(masks_file)

def return_file_names_df(root_dir):
    # write the code that will create a dataframe with two columns ['images', 'json']
    # the column 'image' will have path to images
    # the column 'json' will have path to json files
    data_df = pd.DataFrame()
    data_df['image'] = images_file
    data_df['json'] = masks_file
    return data_df

root_dir = 'data'
data_df = return_file_names_df(root_dir)
data_df.head()

"""> If you observe the dataframe, we can consider each row as single data point, where first feature is image and the second feature is corresponding json file"""

def grader_1(data_df):
    for i in data_df.values:
        if not (path.isfile(i[0]) and path.isfile(i[1]) and i[0][12:i[0].find('_')]==i[1][10:i[1].find('_')]):
            return False
    return True

grader_1(data_df)

data_df.shape

"""## 2. Structure of sample Json file

#### Compute the unique labels

Let's see how many unique objects are there in the json file.
to see how to get the object from the json file please check <a href='https://www.geeksforgeeks.org/read-json-file-using-python/'>this blog </a>
"""

def return_unique_labels(data_df):
    # for each file in the column json
    #       read and store all the objects present in that file
    # compute the unique objects and retrun them
    # if open any json file using any editor you will get better sense of it
    labels = set()
    label_k = 0
    for filename in data_df['json']:
      with open(filename) as f:
        data = json.load(f)
        #data_new = json.dumps(data, indent=2)
        for i in data['objects']:
          if i['label'] not in labels:
            label_k = label_k + 1
            labels.add(i['label'])
    #label_k, labels
    return list(labels)

unique_labels = return_unique_labels(data_df)

len(unique_labels)

label_clr = {'road':10, 'parking':20, 'drivable fallback':20,'sidewalk':30,'non-drivable fallback':40,'rail track':40,\
                        'person':50, 'animal':50, 'rider':60, 'motorcycle':70, 'bicycle':70, 'autorickshaw':80,\
                        'car':80, 'truck':90, 'bus':90, 'vehicle fallback':90, 'trailer':90, 'caravan':90,\
                        'curb':100, 'wall':100, 'fence':110,'guard rail':110, 'billboard':120,'traffic sign':120,\
                        'traffic light':120, 'pole':130, 'polegroup':130, 'obs-str-bar-fallback':130,'building':140,\
                        'bridge':140,'tunnel':140, 'vegetation':150, 'sky':160, 'fallback background':160,'unlabeled':0,\
                        'out of roi':0, 'ego vehicle':170, 'ground':180,'rectification border':190,\
                   'train':200}

def grader_2(unique_labels):
    if (not (set(label_clr.keys())-set(unique_labels))) and len(unique_labels) == 40:
        print("True")
    else:
        print("Flase")

grader_2(unique_labels)

list_classes = [label_clr[key] for key in label_clr.keys()]
list_classes = list(set(list_classes))
list_classes = [int(cvf/10) for cvf in list_classes]
list_classes.sort()
print(list_classes, '\n',len(list_classes))

"""<pre>
* here we have given a number for each of object types, if you see we are having 21 different set of objects
* Note that we have multiplies each object's number with 10, that is just to make different objects look differently in the segmentation map
* Before you pass it to the models, you might need to devide the image array /10.
</pre>

## 3. Extracting the polygons from the json files
"""

def get_poly(file):
    # this function will take a file name as argument
    
    # it will process all the objects in that file and returns
    
    # label: a list of labels for all the objects label[i] will have the corresponding vertices in vertexlist[i]
    # len(label) == number of objects in the image
    
    # vertexlist: it should be list of list of vertices in tuple formate 
    # ex: [[(x11,y11), (x12,y12), (x13,y13) .. (x1n,y1n)]
    #     [(x21,y21), (x22,y12), (x23,y23) .. (x2n,y2n)]
    #      .....
    #     [(xm1,ym1), (xm2,ym2), (xm3,ym3) .. (xmn,ymn)]]
    # len(vertexlist) == number of objects in the image
    
    # * note that label[i] and vertextlist[i] are corresponds to the same object, one represents the type of the object
    # the other represents the location
    
    # width of the image
    # height of the image
    with open(file) as file:
      label = []
      vertexlist = []
      data = json.load(file)
      h = data['imgHeight']
      w = data['imgWidth']
      for i in data['objects']:
        label.append(i['label'])
        list_vertices = []
        for j in i['polygon']:
          list_vertices.append(tuple(j))
        vertexlist.append(list_vertices)
    return w, h, label, vertexlist

def grader_3(file):
    w, h, labels, vertexlist = get_poly(file)
    print(len((set(labels)))==18 and len(vertexlist)==227 and w==1920 and h==1080 \
          and isinstance(vertexlist,list) and isinstance(vertexlist[0],list) and isinstance(vertexlist[0][0],tuple) )

grader_3('data/mask/201/frame0029_gtFine_polygons.json')

"""## 4. Creating Image segmentations by drawing set of polygons"""

def compute_masks(data_df):
    # after you have computed the vertexlist plot that polygone in image like this
    
    # img = Image.new("RGB", (w, h))
    # img1 = ImageDraw.Draw(img)
    # img1.polygon(vertexlist[i], fill = label_clr[label[i]])
    
    # after drawing all the polygons that we collected from json file, 
    # you need to store that image in the folder like this "data/output/scene/framenumber_gtFine_polygons.png"
    
    # after saving the image into disk, store the path in a list
    # after storing all the paths, add a column to the data_df['mask'] ex: data_df['mask']= mask_paths
    #try:
    masks_all = []
    for i in tqdm(range(len(data_df['json']))):
      file_img = data_df['image'][i]
      file_json = (data_df['json'][i])
      file_mask = file_json.replace('/mask/', '/output/')
      file_mask = file_mask.replace('.json', '.png')
      w, h, labels, vertexlist = get_poly(file_json)
      img2 = Image.new("RGB", (w, h))
      img12 = ImageDraw.Draw(img2)
      for i in range(len(vertexlist)):
        #'data/mask/354/frame0011_gtFine_polygons.json' is having single pair of coordinates--
        #--for one 'vegetation' type label and also empty lists: Polygon can't be drawn in such case--
        #--ImageDraw.Draw.polygon() Method needs Sequence of 2-tuples like [(x, y), (x, y), â€¦]
        #--Therefore Ignoring that and such type of Polygons
        if len(vertexlist[i])==1 or len(vertexlist[i])==0:       
          continue
        img12.polygon(vertexlist[i], fill = label_clr[labels[i]])
      img2=np.array(img2)
      dir_mask = ('/').join(file_mask.split(sep='/')[0:3])
      #img4 = Image.fromarray(img2, 'RGB')
      if not os.path.exists(dir_mask):
          os.makedirs(dir_mask)
      img4 = Image.fromarray(img2[:,:,0])
      img4.save(file_mask)
      masks_all.append(file_mask)
    data_df['mask'] = masks_all
      # img5 = mpimg.imread(file_mask)      ## Mask Image
      # #imgplot = plt.imshow(img5[:,:,0])  ## Mask Image
      # img222 = mpimg.imread(file_img)     ## Original Image
      # #imgplot22 = plt.imshow(img222)     ## Original Image
    return data_df

from tqdm import tqdm
data_df = compute_masks(data_df)
data_df.head()

import urllib.request
def grader_3():
    url = "https://i.imgur.com/4XSUlHk.png"
    url_response = urllib.request.urlopen(url)
    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)
    img = cv2.imdecode(img_array, -1)
    my_img = cv2.imread('data/output/201/frame0029_gtFine_polygons.png')    
    plt.imshow(my_img)
    print((my_img[:,:,0]==img).all())
    print(np.unique(img))
    print(np.unique(my_img[:,:,:]))
    data_df.to_csv('preprocessed_data.csv', index=False)
grader_3()

"""# Task 2: Applying Unet to segment the images"""

import tensorflow as tf
# tf.enable_eager_execution()
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
# from hilbert import hilbertCurve
import imgaug.augmenters as iaa
import numpy as np
# import albumentations as A
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

from tensorflow.keras import layers
from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten, LSTM, BatchNormalization, ReLU, Reshape
from tensorflow.keras.models import Model
import random as rn

!pip install imgaug

from tensorflow.keras.layers import Flatten

from sklearn.model_selection import train_test_split
X_train, X_test = train_test_split(data_df, test_size=0.12, random_state=42)
X_train.shape, X_test.shape

!pip install -U segmentation-models==0.2.1

# we are importing the pretrained unet from the segmentation models
# https://github.com/qubvel/segmentation_models
import segmentation_models as sm
from segmentation_models import Unet
# sm.set_framework('tf.keras')
tf.keras.backend.set_image_data_format('channels_last')

# loading the unet model and using the resnet 34 and initilized weights with imagenet weights
# "classes" :different types of classes in the dataset
tf.keras.backend.clear_session()
model = Unet('resnet34', encoder_weights='imagenet', classes=21, activation='softmax', input_shape=(256,256,3))

model.summary()

# import imgaug.augmenters as iaa
# For the assignment choose any 4 augumentation techniques
# check the imgaug documentations for more augmentations
aug2 = iaa.Fliplr(1)
aug3 = iaa.Flipud(1)
aug4 = iaa.Emboss(alpha=(1), strength=1)
aug5 = iaa.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))
#aug6 = iaa.Sharpen(alpha=(1.0), lightness=(1.5))

def visualize(**images):
    n = len(images)
    plt.figure(figsize=(16, 5))
    for i, (name, image) in enumerate(images.items()):
        plt.subplot(1, n, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.title(' '.join(name.split('_')).title())
        if i==1:
            plt.imshow(image, cmap='gray', vmax=1, vmin=0)
        else:
            plt.imshow(image)
    plt.show()
    
# def normalize_image(mask):
#     mask = mask/255
#     return mask

class Dataset:
    # we will be modifying this CLASSES according to your data/problems
    CLASSES = list_classes
    
    # the parameters needs to changed based on your requirements
    # here we are collecting the file_names because in our dataset, both our images and maks will have same file name
    # ex: fil_name.jpg   file_name.mask.jpg
    def __init__(self, file_names, classes, train_sett):
        
        ###self.ids = file_names
        # the paths of images
        self.images_fps   = list(file_names['image'])###[os.path.join(images_dir, image_id+'.jpg') for image_id in self.ids]
        # the paths of segmentation images
        self.masks_fps    = list(file_names['mask'])###[os.path.join(images_dir, image_id+".mask.jpg") for image_id in self.ids]
        # the paths of json files
        # self.json_fps     = file_names['json']
        # giving labels for each class
        self.class_values = [self.CLASSES.index(cls) for cls in classes]
        self.train_sett = train_sett
        self.w = 256
        self.h = 256
    
    def __getitem__(self, i):
        
        # read data

        # self.w, self.h, self.labels_d, self.vertexlist_d = get_poly(self.json_fps[i])

        ###image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)

        image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED) 
        image = cv2.resize(image,(self.w,self.h),interpolation=cv2.INTER_NEAREST)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        image_mask  = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)/10
        image_mask = cv2.resize(image_mask,(self.w,self.h),interpolation=cv2.INTER_NEAREST)
        ###image_mask = normalize_image(mask)

        
        image_masks = [(image_mask == v) for v in self.class_values]
        image_mask = np.stack(image_masks, axis=-1).astype('float')
   
        if self.train_sett=='train':
            a = np.random.uniform()
            if a<0.3:
                image = aug2.augment_image(image)
                image_mask = aug2.augment_image(image_mask)
            elif a<0.6:
                image = aug3.augment_image(image)
                image_mask = aug3.augment_image(image_mask)
            elif a<0.8:
                image = aug4.augment_image(image)
                image_mask = aug4.augment_image(image_mask)
            else:
                image = aug5.augment_image(image)
                image_mask = image_mask
            
        return image, image_mask
        
    def __len__(self):
        return len(self.ids)
    
    
class Dataloder(tf.keras.utils.Sequence):    
    def __init__(self, dataset, batch_size=1, len_shape=3527, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len_shape)

    def __getitem__(self, i):
        
        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            data.append(self.dataset[j])
        
        batch = [np.stack(samples, axis=0) for samples in zip(*data)]
        
        return tuple(batch)
    
    def __len__(self):
        return len(self.indexes) // self.batch_size
    
    def on_epoch_end(self):
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)

# https://github.com/qubvel/segmentation_models
import segmentation_models as sm
from segmentation_models.metrics import iou_score
from segmentation_models import Unet
import tensorflow
import keras

optim = keras.optimizers.Adam(learning_rate=0.000086)

focal_loss = sm.losses.cce_dice_loss

# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses
# total_loss = sm.losses.binary_focal_dice_loss 
# or total_loss = sm.losses.categorical_focal_dice_loss 

model.compile(optimizer = optim, loss = focal_loss, metrics=[iou_score])

#Remove Previous Logs
import shutil
shutil.rmtree('logs\Model_Unet', ignore_errors=True)

#Function for Custom Callback for Implementing Micro Averaged F1 Score as the Metric
import numpy as np
from tensorflow.keras.callbacks import Callback
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
class Metrics(Callback):
  def __init__(self, interval=1):
    super(Callback, self).__init__()
    self.interval = interval
    #self.X_val, self.y_val = validation_data
  #def on_train_begin(self, logs={}):
  
  def on_epoch_end(self, epoch, logs={}):
    if epoch % self.interval == 0:
      #Checking Overfitting after achieving desired val_iou_score
      #if logs.get('val_iou_score')>0.50: #or logs.get('iou_score')>0.50:# and logs.get('accuracy')>0.75:
      #if (logs.get('accuracy')-logs.get('val_accuracy'))>0.06:
      #    print("Required Metric Value Reached, hence terminated at epoch {} to prevent overfitting".format(epoch))
      #    self.model.stop_training = True
      # if logs.get('iou_score')>0.50:
      #     print("Required metric reached, hence terminated at epoch {} to prevent overfitting".format(epoch))
      #     self.model.stop_training = True
      if (logs.get('iou_score')-logs.get('val_iou_score'))>0.30 and logs.get('iou_score')>=0.50:
          print("Overfitting started, hence terminated at epoch {} to prevent furthur overfitting".format(epoch))
          self.model.stop_training = True
      return
 
metrics = Metrics(interval=1)

import keras
# Dataset for train images
CLASSES = list_classes
train_dataset = Dataset(X_train, classes=CLASSES, train_sett='train')
test_dataset  = Dataset(X_test, classes=CLASSES, train_sett='test')


train_dataloader = Dataloder(train_dataset, batch_size=16, len_shape=3527, shuffle=True)
test_dataloader = Dataloder(test_dataset, batch_size=16, len_shape=481, shuffle=True)

print(train_dataloader[0][0].shape, train_dataloader[0][1].shape)
BATCH_SIZE = 8
assert train_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)
assert train_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, 21)

NAME = "Model_Unet"
# define callbacks for learning rate scheduling and best checkpoints saving
callbacks = [
    keras.callbacks.TensorBoard(log_dir='logs\{}'.format(NAME),update_freq='epoch'),
    keras.callbacks.ModelCheckpoint('./best_model_unet.h5', save_weights_only=False, save_best_only=True, \
                                       mode='max', monitor='val_iou_score'),
    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.00000001,patience=2),
    metrics
]

!rm -rf /logs

history_unet = model.fit(train_dataloader, steps_per_epoch=len(train_dataloader), 
                              epochs=100, validation_data=test_dataloader,callbacks=callbacks)

# Plot training & validation iou_score values
plt.figure(figsize=(30, 5))
plt.subplot(121)
plt.plot(history_unet.history['iou_score'])
plt.plot(history_unet.history['val_iou_score'])
plt.title('Model iou_score')
plt.ylabel('iou_score')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

# Plot training & validation loss values
plt.subplot(122)
plt.plot(history_unet.history['loss'])
plt.plot(history_unet.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

X_test_ex = X_test.head(10)
for p in range(10):
    #original image
    image = cv2.imread(list(X_test_ex['image'])[p], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (256,256),interpolation = cv2.INTER_NEAREST) 
    
    #predicted segmentation map
    pred_mask  = model.predict(image[np.newaxis,:,:,:])
    pred_mask = tf.argmax(pred_mask, axis=-1)
    
    #original segmentation map
    image_mask = cv2.imread(list(X_test_ex['mask'])[p], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (256,256),interpolation = cv2.INTER_NEAREST)
    

    plt.figure(figsize=(10,6))
    plt.subplot(131)
    plt.imshow(image)   #Original Image
    plt.subplot(132)
    plt.imshow(image_mask, cmap='gray')   #Original Mask
    plt.subplot(133)
    plt.imshow(pred_mask[0], cmap='gray') #Predicted Mask
    plt.show()